我们在开始之前说一下我们要干什么。在这篇文章中，我们要干三件事：

1. 初始化参数：
	1.1：使用0来初始化参数。
	1.2：使用随机数来初始化参数。
	1.3：使用抑梯度异常初始化参数（参见视频中的梯度消失和梯度爆炸）。
	总结：
		不同的初始化方法可能导致性能最终不同
		随机初始化有助于打破对称，使得不同隐藏层的单元可以学习到不同的参数。
		初始化时，初始值不宜过大。
		He初始化搭配ReLU激活函数常常可以得到不错的效果。
		在深度学习中，如果数据集没有足够大的话，可能会导致一些过拟合的问题。过拟合导致的结果就是在训练集上有着很高的精确度，但是在遇到新的样本时，精确度下降会很严重。为了避免过拟合的问题，接下来我们要讲解的方式就是正则化

2. 正则化模型：
    2.1：使用二范数对二分类模型正则化，尝试避免过拟合。
    2.2：使用随机删除节点的方法精简模型，同样是为了尝试避免过拟合。
3. 梯度校验  ：对模型使用梯度校验，检测它是否在梯度下降的过程中出现误差过大的情况。

